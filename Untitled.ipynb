{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8e641f3-f2a3-4de2-af9b-e942ae42ce32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "121d32a3-4116-4237-8552-ae64968c3c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.argv = ['script_name', '-i', '../../300-W/labels_ibug_300W_train.xml', '-t', '../../300-W/train_output.xml']\n",
    "\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-i\", \"--input\", required=True,\n",
    "    help=\"../../300-W/labels_ibug_300W_train.xml\")\n",
    "ap.add_argument(\"-t\", \"--output\", required=True,\n",
    "    help=\"../../300-W/train_output.xml\")\n",
    "args = vars(ap.parse_args())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18c62c79-0201-4423-b7e0-155435661ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in the iBUG 300-W dataset, each (x, y)-coordinate maps to a specific\n",
    "# facial feature (i.e., eye, mouth, nose, etc.) -- in order to train a\n",
    "# dlib shape predictor on *just* the eyes, we must first define the\n",
    "# integer indexes that belong to the eyes\n",
    "LANDMARKS = set(list(range(36, 48)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b47ffa7a-e90e-4e24-8e99-962a92bfe176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] parsing data split XML file...\n"
     ]
    }
   ],
   "source": [
    "# to easily parse out the eye locations from the XML file we can\n",
    "# utilize regular expressions to determine if there is a 'part'\n",
    "# element on any given line\n",
    "PART = re.compile(\"part name='[0-9]+'\")\n",
    "# load the contents of the original XML file and open the output file\n",
    "# for writing\n",
    "print(\"[INFO] parsing data split XML file...\")\n",
    "rows = open(args[\"input\"]).read().strip().split(\"\\n\")\n",
    "output = open(args[\"output\"], \"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82c810f4-369a-4552-8651-dd783c7104e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over the rows of the data split file\n",
    "for row in rows:\n",
    "\t# check to see if the current line has the (x, y)-coordinates for\n",
    "\t# the facial landmarks we are interested in\n",
    "\tparts = re.findall(PART, row)\n",
    "\t# if there is no information related to the (x, y)-coordinates of\n",
    "\t# the facial landmarks, we can write the current line out to disk\n",
    "\t# with no further modifications\n",
    "\tif len(parts) == 0:\n",
    "\t\toutput.write(\"{}\\n\".format(row))\n",
    "\t# otherwise, there is annotation information that we must process\n",
    "\telse:\n",
    "\t\t# parse out the name of the attribute from the row\n",
    "\t\tattr = \"name='\"\n",
    "\t\ti = row.find(attr)\n",
    "\t\tj = row.find(\"'\", i + len(attr) + 1)\n",
    "\t\tname = int(row[i + len(attr):j])\n",
    "\t\t# if the facial landmark name exists within the range of our\n",
    "\t\t# indexes, write it to our output file\n",
    "\t\tif name in LANDMARKS:\n",
    "\t\t\toutput.write(\"{}\\n\".format(row))\n",
    "# close the output file\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3475d35-c4df-4773-a4d4-31bbe0469b3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
